{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from hdfs import InsecureClient\n",
    "import numpy as np\n",
    "import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through the base path and find all the .h5 files that are present there then save them to a csv file in order to load them later into spark\n",
    "\n",
    "TODO: this actually needs to be reworked to create a table based on the hdfs file directory instead of local, however it doesn't matter as long as we don't change the files just run the code and pretend it does the right thing for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basedir = '../MillionSongSubset/data'\n",
    "# os.listdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../MillionSongSubset/data/files.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5a4d1b08a16c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mflat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_files\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/files.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../MillionSongSubset/data/files.csv'"
     ]
    }
   ],
   "source": [
    "ext='.h5'\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(basedir):\n",
    "    #print(root, dirs, f)\n",
    "    files = glob.glob(os.path.join(root,'*'+ext))\n",
    "    all_files.append(files)\n",
    "\n",
    "flat_list = [item for sublist in all_files for item in sublist]\n",
    "file = '/files.csv'\n",
    "with open(basedir + file, 'w', newline='') as myfile:\n",
    "    for line in flat_list:\n",
    "        myfile.write(line)\n",
    "        myfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the spark application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of partitions we want for the rdds\n",
    "num_nodes = 3\n",
    "num_rep = 2 * num_nodes\n",
    "#sc.stop()\n",
    "conf = (SparkConf()\n",
    "   .setMaster(\"spark://192.168.2.110:7077\")\n",
    "   .setAppName(\"Group14\")\n",
    "   .set(\"spark.executor.cores\", 2) # if anything >2, does not run\n",
    "   .set(\"spark.pytspark.python\",\"python3\")\n",
    "   .set(\"spark.dynamicAllocation.enabled\", False)\n",
    "   .set(\"spark.shuffle.service.enabled\", False)\n",
    "   .set(\"spark.executor.memory\", \"2g\")\n",
    "   .set(\"spark.local.dir\", \"/home/ubuntu/MillionSong/spark/tmp\"))\n",
    "\n",
    "#sc = SparkContext(conf = conf)\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to convert filenames to actual file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good methods to explore the h5 inread: .keys(), .attrs.items() see documentation of h5py\n",
    "\n",
    "def get_title(file, idx=0):\n",
    "    return file['metadata']['songs']['title'][idx].decode(\"utf-8\")\n",
    "\n",
    "def get_artist_name(file, idx=0):\n",
    "    return file['metadata']['songs']['artist_name'][idx].decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_artist_familiarity(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist familiarity from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['artist_familiarity'][songidx]).encode('utf-8', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_artist_hotttnesss(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist hotttnesss from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['artist_hotttnesss'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_artist_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5['metadata']['songs']['artist_id'][songidx].decode(\"utf-8\")\n",
    "\n",
    "def get_artist_mbid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musibrainz id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5['metadata']['songs']['artist_mbid'][songidx].decode(\"utf-8\")\n",
    "\n",
    "def get_artist_playmeid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist playme id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['artist_playmeid'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_artist_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['artist_7digitalid'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_artist_latitude(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist latitude from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['artist_latitude'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_artist_longitude(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist longitude from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['artist_longitude'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_artist_location(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist location from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5['metadata']['songs']['artist_location'][songidx].decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_release(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5['metadata']['songs']['release'][songidx].decode(\"utf-8\")\n",
    "\n",
    "def get_release_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['release_7digitalid'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_song_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5['metadata']['songs']['song_id'][songidx].decode(\"utf-8\")\n",
    "\n",
    "def get_song_hotttnesss(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song hotttnesss from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['song_hotttnesss'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_track_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get track 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['metadata']['songs']['track_7digitalid'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_analysis_sample_rate(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get analysis sample rate from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['analysis_sample_rate'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_audio_md5(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get audio MD5 from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5['analysis']['songs']['audio_md5'][songidx].decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_danceability(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get danceability from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['danceability'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_duration(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get duration from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['duration'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_end_of_fade_in(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get end of fade in from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['end_of_fade_in'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_energy(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get energy from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['energy'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_key(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get key from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['key'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_key_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get key confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['key_confidence'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_loudness(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get loudness from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['loudness'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_mode(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get mode from a HDF5 song file, by default the first song ifn it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['mode'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_mode_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get mode confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['mode_confidence'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_start_of_fade_out(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get start of fade out from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['start_of_fade_out'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def get_tempo(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tempo from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['tempo'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_time_signature(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get signature from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['time_signature'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_time_signature_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get signature confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['time_signature_confidence'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_track_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get track id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['analysis']['songs']['track_id'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")\n",
    "\n",
    "def get_year(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release year from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return str(h5['musicbrainz']['songs']['year'][songidx]).encode('utf-8','ignore').decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(x):\n",
    "    import io\n",
    "    import h5py\n",
    "    with h5py.File(io.BytesIO(x), 'r') as f:\n",
    "        song = []\n",
    "        \n",
    "        song.append(get_artist_name(f))\n",
    "        song.append(get_title(f))\n",
    "        song.append(get_artist_familiarity(f))\n",
    "        song.append(get_artist_hotttnesss(f))\n",
    "        song.append(get_artist_id(f))\n",
    "        song.append(get_artist_mbid(f))\n",
    "        song.append(get_artist_playmeid(f))\n",
    "        song.append(get_artist_7digitalid(f))\n",
    "        song.append(get_artist_latitude(f))\n",
    "        song.append(get_artist_longitude(f))\n",
    "        song.append(get_artist_location(f))\n",
    "        song.append(get_release(f))\n",
    "        song.append(get_release_7digitalid(f))\n",
    "        song.append(get_song_id(f))\n",
    "        song.append(get_song_hotttnesss(f))\n",
    "        song.append(get_track_7digitalid(f))\n",
    "        song.append(get_analysis_sample_rate(f))\n",
    "        song.append(get_audio_md5(f))\n",
    "        song.append(get_danceability(f))\n",
    "        song.append(get_duration(f))\n",
    "        song.append(get_end_of_fade_in(f))\n",
    "        song.append(get_energy(f))\n",
    "        song.append(get_key(f))\n",
    "        song.append(get_key_confidence(f))\n",
    "        song.append(get_loudness(f))\n",
    "        song.append(get_mode(f))\n",
    "        song.append(get_mode_confidence(f))\n",
    "        song.append(get_start_of_fade_out(f))\n",
    "        song.append(get_tempo(f))\n",
    "        song.append(get_time_signature(f))\n",
    "        song.append(get_time_signature_confidence(f))\n",
    "        song.append(get_track_id(f))\n",
    "        song.append(get_year(f))\n",
    "        \n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 45.8726 seconds\n"
     ]
    }
   ],
   "source": [
    "def read_in(numberData):\n",
    "    with open(\"/home/ubuntu/files.csv\", \"r\", newline=\"\\n\") as f:\n",
    "        results = [line.split(',')[-1][1:-2] for line in f]\n",
    "    results = results[0:1000]\n",
    "    df = sc.union([sc.binaryFiles(\"hdfs://192.168.2.110:9000\" + f) for f in results])\n",
    "    return df\n",
    "\n",
    "\n",
    "def map_h5_to_df(df):\n",
    "    df_mapped = df.map(lambda x: read(x[1]))\n",
    "    return df_mapped\n",
    "\n",
    "def convert_to columns(df_mapped):\n",
    "    columns = ['artist_name', 'title', 'artist_familiarity', \n",
    "                 'artist_hotttnesss', 'artist_id', 'artist_mbid', \n",
    "                 'artist_playmeid', 'artist_7digitalid', 'artist_latitude', \n",
    "                 'artist_longitude', 'artist_location', 'release', \n",
    "                 'release_7digitalid', \n",
    "                 'song_id', 'song_hotnesss', 'track_7digitalid', \n",
    "                 'analysis_sample_rate', \n",
    "                 'audio_md5', 'danceability', 'duration', 'end_of_fade_in', \n",
    "                 'energy', 'key', \n",
    "                 'key_confidence', 'loudness', 'mode', 'mode_confidence', \n",
    "                 'start_of_fade_out', \n",
    "                 'tempo', 'time_signature', \n",
    "                 'time_signature_confidence', 'track_id', 'year']\n",
    "    df = df_mapped.toDF(columns)\n",
    "    return df\n",
    "\n",
    "def change_types(df):\n",
    "    from pyspark.sql import types \n",
    "    ['BinaryType', 'BooleanType', 'ByteType', 'DateType', \n",
    "              'DecimalType', 'DoubleType', 'FloatType', 'IntegerType', \n",
    "               'LongType', 'ShortType', 'StringType', 'TimestampType']\n",
    "    changedTypedf = df.withColumn(\"year\", df[\"year\"].cast(\"Integer\"))\\\n",
    "                    .withColumn(\"track_id\", df[\"track_id\"].cast(\"Integer\"))\\\n",
    "                    .withColumn(\"artist_id\", df[\"artist_id\"].cast(\"Integer\"))\\\n",
    "                    .withColumn(\"song_id\", df[\"song_id\"].cast(\"Integer\"))\\\n",
    "                    .withColumn(\"duration\", df[\"duration\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"danceability\", df[\"danceability\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"end_of_fade_in\", df[\"end_of_fade_in\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"energy\", df[\"energy\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"key_confidence\", df[\"key_confidence\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"mode_confidence\", df[\"mode_confidence\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"release_7digitalid\", df[\"release_7digitalid\"].cast(\"Integer\"))\\\n",
    "                    .withColumn(\"song_hotnesss\", df[\"song_hotnesss\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"start_of_fade_out\", df[\"start_of_fade_out\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"loudness\", df[\"loudness\"].cast(\"Float\"))\\\n",
    "                    .withColumn(\"tempo\", df[\"tempo\"].cast(\"Float\"))\n",
    "    return changedTypedf\n",
    "\n",
    "\n",
    "def groupByArtist(changedTypedf):\n",
    "    changedTypedf.groupBy('artist_name')\\\n",
    "                 .count()\\\n",
    "                 .show()\n",
    "    \n",
    "def groupByYear(changedTypedf):\n",
    "    changedTypedf.groupBy('year')\\\n",
    "                 .count()\\\n",
    "                 .show()\n",
    "    \n",
    "    \n",
    "def analysis(changedTypedf):\n",
    "    from pyspark.sql.functions import col, avg\n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark.sql.functions import *\n",
    "\n",
    "    left = changedTypedf.select(\"artist_name\").distinct().filter(changedTypedf['year'] > 2000)\n",
    "\n",
    "    right = changedTypedf.groupBy(\"artist_name\")\\\n",
    "                .agg(avg(col(\"loudness\"))\\\n",
    "                .alias(\"avg_loudness\"))\\\n",
    "                .orderBy(\"avg_loudness\", ascending=False)\n",
    "\n",
    "    avg_loudness = left.join(right, left.artist_name == right.artist_name)\\\n",
    "                .select(right[\"artist_name\"], \"avg_loudness\")\\\n",
    "                .orderBy(\"avg_loudness\", ascending=False)\\\n",
    "                .collect()\n",
    "    return avg_loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('experiment.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    header= ['elements', \"readin\", \"mapping\", \"converting\", \"changetypes\", \n",
    "             \"GroupByArtist\", \"GroupByYear\", \"Analysis\"]\n",
    "    writer.writerow (header)\n",
    "    for elements in [100, 1000, 5000, 10000]:\n",
    "        for i in range(5):\n",
    "            times = []\n",
    "            times.append(elements)\n",
    "            \n",
    "            tic = time.perf_counter()\n",
    "            df = read_in(elements)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "            \n",
    "            tic = time.perf_counter()\n",
    "            mapped = map_h5_to_df(df)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "\n",
    "            tic = time.perf_counter()\n",
    "            converted = convert_to columns(mapped)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "            \n",
    "            tic = time.perf_counter()\n",
    "            changed = change_types(converted)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "            \n",
    "            tic = time.perf_counter()\n",
    "            groupByArtist(changed)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "            \n",
    "            tic = time.perf_counter()\n",
    "            groupByYear(changed)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "            \n",
    "            tic = time.perf_counter()\n",
    "            analysed = analysis(changed)\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"It took {toc - tic:0.4f} seconds\")\n",
    "            times.append(toc - tic:0.4f)\n",
    "            \n",
    "            writer.writeRow(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
